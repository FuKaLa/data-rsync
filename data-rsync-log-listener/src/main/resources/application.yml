spring:
  application:
    name: data-rsync-log-listener
  
  # Redis 配置
  redis:
    host: localhost
    port: 6379
    password:
    database: 0
  
  # Kafka 配置
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: 1
      batch-size: 16384
      linger-ms: 1
      buffer-memory: 33554432
  
  # Nacos 配置
  cloud:
    nacos:
      discovery:
        server-addr: localhost:8848
        namespace: public
      config:
        server-addr: localhost:8848
        namespace: public
        file-extension: yml

# 服务器配置
server:
  port: 8082
  servlet:
    context-path: /log-listener

# 日志配置
logging:
  level:
    root: info
    com.data.rsync.log.listener: debug

# 日志监听配置
log-listener:
  debezium:
    offset:
      storage: /tmp/debezium/offsets
      flush-interval: 60000 # 偏移量刷新间隔（毫秒）
    history:
      storage: /tmp/debezium/history
  full-scan:
    enabled: true # 是否启用全量扫描
    shard:
      max-count: 10 # 最大分片数
      batch-size: 1000 # 分片批量大小
  breakpoint:
    enabled: true # 是否启用断点续传
    redis-key-prefix: breakpoint: # 断点续传 Redis 键前缀
  thread:
    pool-size: 10 # 线程池大小
  health-check:
    interval: 60000 # 健康检查间隔（毫秒）